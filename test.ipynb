{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket split into two new buckets\n",
      "004\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node_id):\n",
    "        self.id = node_id\n",
    "\n",
    "class KBucket:\n",
    "    def __init__(self, depth, capacity=3, range_start=0, range_end=(1 << 160) - 1):\n",
    "        self.nodes = []\n",
    "        self.capacity = capacity\n",
    "        self.depth = depth\n",
    "        self.range_start = range_start\n",
    "        self.range_end = range_end\n",
    "\n",
    "    def insert_node(self, node_id):\n",
    "        if len(self.nodes) < self.capacity:\n",
    "            self.nodes.append(Node(node_id))\n",
    "        else:\n",
    "            if self.node_in_bucket_range(node_id):\n",
    "                self.split_bucket()\n",
    "                self.insert_node(node_id)\n",
    "            else:\n",
    "                # 节点ID不在当前桶范围，丢弃\n",
    "                print(f\"Node {node_id} outside of bucket range, discarded.\")\n",
    "\n",
    "    def node_in_bucket_range(self, node_id):\n",
    "        # 判断节点ID是否在当前桶的范围内\n",
    "        node_id_num = int(node_id, 16)\n",
    "        return self.range_start <= node_id_num <= self.range_end\n",
    "\n",
    "    def split_bucket(self):\n",
    "        mid_point = (self.range_start + self.range_end) // 2\n",
    "        left_bucket = KBucket(self.depth + 1, self.capacity, self.range_start, mid_point)\n",
    "        right_bucket = KBucket(self.depth + 1, self.capacity, mid_point + 1, self.range_end)\n",
    "        \n",
    "        # 重新分配当前桶中的所有节点\n",
    "        for node in self.nodes:\n",
    "            if self.range_start <= int(node.id, 16) <= mid_point:\n",
    "                left_bucket.nodes.append(node)\n",
    "            else:\n",
    "                right_bucket.nodes.append(node)\n",
    "        \n",
    "        # 为了简化，只保留一个桶\n",
    "        self.nodes = []\n",
    "        self.nodes.extend(left_bucket.nodes if len(left_bucket.nodes) <= len(right_bucket.nodes) else right_bucket.nodes)\n",
    "        self.range_start = left_bucket.range_start if len(left_bucket.nodes) <= len(right_bucket.nodes) else right_bucket.range_start\n",
    "        self.range_end = left_bucket.range_end if len(left_bucket.nodes) <= len(right_bucket.nodes) else right_bucket.range_end\n",
    "\n",
    "        print(\"Bucket split into two new buckets\")\n",
    "\n",
    "    def printBucketContents(self):\n",
    "        for node in self.nodes:\n",
    "            print(node.id)\n",
    "\n",
    "# 示例\n",
    "bucket = KBucket(depth=0)\n",
    "bucket.insert_node('001')\n",
    "bucket.insert_node('002')\n",
    "bucket.insert_node('003')\n",
    "bucket.insert_node('004')  # 触发分裂\n",
    "bucket.printBucketContents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing basic insertion...\n",
      "Basic insertion passed.\n",
      "Testing bucket split...\n",
      "Bucket split into two new buckets\n",
      "Bucket split passed, remaining nodes: 1\n",
      "Testing node discard...\n",
      "Node 003 outside of bucket range, discarded.\n",
      "Node 005 outside of bucket range, discarded.\n",
      "Node discard passed.\n",
      "Testing print contents...\n",
      "010\n",
      "011\n",
      "012\n",
      "Print contents test complete. Check output manually.\n"
     ]
    }
   ],
   "source": [
    "class TestKBucket:\n",
    "    def __init__(self):\n",
    "        # 初始化一个桶，假定深度为0，容量为3\n",
    "        self.bucket = KBucket(depth=0, capacity=3)\n",
    "\n",
    "    def test_insertion(self):\n",
    "        print(\"Testing basic insertion...\")\n",
    "        self.bucket.insert_node('001')\n",
    "        self.bucket.insert_node('002')\n",
    "        assert len(self.bucket.nodes) == 2, \"Insertion failed!\"\n",
    "        print(\"Basic insertion passed.\")\n",
    "\n",
    "    def test_bucket_split(self):\n",
    "        print(\"Testing bucket split...\")\n",
    "        self.bucket.insert_node('003')\n",
    "        # 第四个节点应触发分裂\n",
    "        self.bucket.insert_node('004')\n",
    "        # 根据实际逻辑，节点应该仍然存在于一个新桶中\n",
    "        assert len(self.bucket.nodes) > 0, \"Bucket did not manage nodes correctly.\"\n",
    "        print(f\"Bucket split passed, remaining nodes: {len(self.bucket.nodes)}\")\n",
    "\n",
    "    def test_node_discard(self):\n",
    "        print(\"Testing node discard...\")\n",
    "        # 填充桶，以确保桶已满\n",
    "        self.bucket.insert_node('001')\n",
    "        self.bucket.insert_node('002')\n",
    "        self.bucket.insert_node('003')\n",
    "        # print(f\"Initial bucket nodes: {[node.id for node in self.bucket.nodes]}\")\n",
    "        \n",
    "        original_node_in_bucket_range = self.bucket.node_in_bucket_range\n",
    "        # 重写桶范围检测逻辑以模拟节点不在范围内的情况\n",
    "        self.bucket.node_in_bucket_range = lambda x: False\n",
    "        self.bucket.insert_node('005')\n",
    "        # 恢复原来的范围检测逻辑\n",
    "        self.bucket.node_in_bucket_range = original_node_in_bucket_range\n",
    "        # print(f\"Bucket nodes after discard attempt: {[node.id for node in self.bucket.nodes]}\")\n",
    "        \n",
    "        assert len(self.bucket.nodes) == 3, \"Node discard failed.\"\n",
    "        print(\"Node discard passed.\")\n",
    "\n",
    "    def test_print_contents(self):\n",
    "        print(\"Testing print contents...\")\n",
    "        # 手动添加节点，用于测试打印\n",
    "        self.bucket.nodes = [Node('010'), Node('011'), Node('012')]\n",
    "        self.bucket.print_contents()\n",
    "        print(\"Print contents test complete. Check output manually.\")\n",
    "\n",
    "# 创建测试实例\n",
    "test = TestKBucket()\n",
    "test.test_insertion()\n",
    "test.test_bucket_split()\n",
    "test.test_node_discard()\n",
    "test.test_print_contents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket split into two new buckets\n",
      "Bucket split into two new buckets\n",
      "Bucket split into two new buckets\n",
      "Node 027 outside of bucket range, discarded.\n",
      "Bucket split into two new buckets\n",
      "Node 034 outside of bucket range, discarded.\n",
      "Node 035 outside of bucket range, discarded.\n",
      "Node 036 outside of bucket range, discarded.\n",
      "Bucket split into two new buckets\n",
      "Node 038 outside of bucket range, discarded.\n",
      "Node 039 outside of bucket range, discarded.\n",
      "Node 040 outside of bucket range, discarded.\n",
      "Node 043 outside of bucket range, discarded.\n",
      "Node 044 outside of bucket range, discarded.\n",
      "Node 045 outside of bucket range, discarded.\n",
      "Node 046 outside of bucket range, discarded.\n",
      "Node 047 outside of bucket range, discarded.\n",
      "Node 048 outside of bucket range, discarded.\n",
      "Node 049 outside of bucket range, discarded.\n",
      "Node 050 outside of bucket range, discarded.\n",
      "Node 051 outside of bucket range, discarded.\n",
      "Node 052 outside of bucket range, discarded.\n",
      "Node 053 outside of bucket range, discarded.\n",
      "Node 054 outside of bucket range, discarded.\n",
      "Node 055 outside of bucket range, discarded.\n",
      "Node 056 outside of bucket range, discarded.\n",
      "Node 057 outside of bucket range, discarded.\n",
      "Node 058 outside of bucket range, discarded.\n",
      "Node 059 outside of bucket range, discarded.\n",
      "Node 060 outside of bucket range, discarded.\n",
      "Node 061 outside of bucket range, discarded.\n",
      "Node 062 outside of bucket range, discarded.\n",
      "Node 063 outside of bucket range, discarded.\n",
      "Node 064 outside of bucket range, discarded.\n",
      "Node 065 outside of bucket range, discarded.\n",
      "Node 066 outside of bucket range, discarded.\n",
      "Node 067 outside of bucket range, discarded.\n",
      "Node 068 outside of bucket range, discarded.\n",
      "Node 069 outside of bucket range, discarded.\n",
      "Node 070 outside of bucket range, discarded.\n",
      "Node 071 outside of bucket range, discarded.\n",
      "Node 072 outside of bucket range, discarded.\n",
      "Node 073 outside of bucket range, discarded.\n",
      "Node 074 outside of bucket range, discarded.\n",
      "Node 075 outside of bucket range, discarded.\n",
      "Node 076 outside of bucket range, discarded.\n",
      "Node 077 outside of bucket range, discarded.\n",
      "Node 078 outside of bucket range, discarded.\n",
      "Node 079 outside of bucket range, discarded.\n",
      "Node 080 outside of bucket range, discarded.\n",
      "Node 081 outside of bucket range, discarded.\n",
      "Node 082 outside of bucket range, discarded.\n",
      "Node 083 outside of bucket range, discarded.\n",
      "Node 084 outside of bucket range, discarded.\n",
      "Node 085 outside of bucket range, discarded.\n",
      "Node 086 outside of bucket range, discarded.\n",
      "Node 087 outside of bucket range, discarded.\n",
      "Node 088 outside of bucket range, discarded.\n",
      "Node 089 outside of bucket range, discarded.\n",
      "Node 090 outside of bucket range, discarded.\n",
      "Node 091 outside of bucket range, discarded.\n",
      "Node 092 outside of bucket range, discarded.\n",
      "Node 093 outside of bucket range, discarded.\n",
      "Node 094 outside of bucket range, discarded.\n",
      "Node 095 outside of bucket range, discarded.\n",
      "Node 096 outside of bucket range, discarded.\n",
      "Node 097 outside of bucket range, discarded.\n",
      "Node 098 outside of bucket range, discarded.\n",
      "Node 099 outside of bucket range, discarded.\n",
      "Node 100 outside of bucket range, discarded.\n",
      "Node 101 outside of bucket range, discarded.\n",
      "Node 102 outside of bucket range, discarded.\n",
      "Node 103 outside of bucket range, discarded.\n",
      "Node 104 outside of bucket range, discarded.\n",
      "Node 105 outside of bucket range, discarded.\n",
      "Node 106 outside of bucket range, discarded.\n",
      "Node 107 outside of bucket range, discarded.\n",
      "Node 108 outside of bucket range, discarded.\n",
      "Node 109 outside of bucket range, discarded.\n",
      "Node 110 outside of bucket range, discarded.\n",
      "Node 111 outside of bucket range, discarded.\n",
      "Node 112 outside of bucket range, discarded.\n",
      "Node 113 outside of bucket range, discarded.\n",
      "Node 114 outside of bucket range, discarded.\n",
      "Node 115 outside of bucket range, discarded.\n",
      "Node 116 outside of bucket range, discarded.\n",
      "Node 117 outside of bucket range, discarded.\n",
      "Node 118 outside of bucket range, discarded.\n",
      "Node 119 outside of bucket range, discarded.\n",
      "Node 120 outside of bucket range, discarded.\n",
      "Node 121 outside of bucket range, discarded.\n",
      "Node 122 outside of bucket range, discarded.\n",
      "Node 123 outside of bucket range, discarded.\n",
      "Node 124 outside of bucket range, discarded.\n",
      "Node 125 outside of bucket range, discarded.\n",
      "Node 126 outside of bucket range, discarded.\n",
      "Node 127 outside of bucket range, discarded.\n",
      "Node 128 outside of bucket range, discarded.\n",
      "Node 129 outside of bucket range, discarded.\n",
      "Node 130 outside of bucket range, discarded.\n",
      "Node 131 outside of bucket range, discarded.\n",
      "Node 132 outside of bucket range, discarded.\n",
      "Node 133 outside of bucket range, discarded.\n",
      "Node 134 outside of bucket range, discarded.\n",
      "Node 135 outside of bucket range, discarded.\n",
      "Node 136 outside of bucket range, discarded.\n",
      "Node 137 outside of bucket range, discarded.\n",
      "Node 138 outside of bucket range, discarded.\n",
      "Node 139 outside of bucket range, discarded.\n",
      "Node 140 outside of bucket range, discarded.\n",
      "Node 141 outside of bucket range, discarded.\n",
      "Node 142 outside of bucket range, discarded.\n",
      "Node 143 outside of bucket range, discarded.\n",
      "Node 144 outside of bucket range, discarded.\n",
      "Node 145 outside of bucket range, discarded.\n",
      "Node 146 outside of bucket range, discarded.\n",
      "Node 147 outside of bucket range, discarded.\n",
      "Node 148 outside of bucket range, discarded.\n",
      "Node 149 outside of bucket range, discarded.\n",
      "Node 150 outside of bucket range, discarded.\n",
      "Node 151 outside of bucket range, discarded.\n",
      "Node 152 outside of bucket range, discarded.\n",
      "Node 153 outside of bucket range, discarded.\n",
      "Node 154 outside of bucket range, discarded.\n",
      "Node 155 outside of bucket range, discarded.\n",
      "Node 156 outside of bucket range, discarded.\n",
      "Node 157 outside of bucket range, discarded.\n",
      "Node 158 outside of bucket range, discarded.\n",
      "Node 159 outside of bucket range, discarded.\n",
      "Node 160 outside of bucket range, discarded.\n",
      "Node 161 outside of bucket range, discarded.\n",
      "Node 162 outside of bucket range, discarded.\n",
      "Node 163 outside of bucket range, discarded.\n",
      "Node 164 outside of bucket range, discarded.\n",
      "Node 165 outside of bucket range, discarded.\n",
      "Node 166 outside of bucket range, discarded.\n",
      "Node 167 outside of bucket range, discarded.\n",
      "Node 168 outside of bucket range, discarded.\n",
      "Node 169 outside of bucket range, discarded.\n",
      "Node 170 outside of bucket range, discarded.\n",
      "Node 171 outside of bucket range, discarded.\n",
      "Node 172 outside of bucket range, discarded.\n",
      "Node 173 outside of bucket range, discarded.\n",
      "Node 174 outside of bucket range, discarded.\n",
      "Node 175 outside of bucket range, discarded.\n",
      "Node 176 outside of bucket range, discarded.\n",
      "Node 177 outside of bucket range, discarded.\n",
      "Node 178 outside of bucket range, discarded.\n",
      "Node 179 outside of bucket range, discarded.\n",
      "Node 180 outside of bucket range, discarded.\n",
      "Node 181 outside of bucket range, discarded.\n",
      "Node 182 outside of bucket range, discarded.\n",
      "Node 183 outside of bucket range, discarded.\n",
      "Node 184 outside of bucket range, discarded.\n",
      "Node 185 outside of bucket range, discarded.\n",
      "Node 186 outside of bucket range, discarded.\n",
      "Node 187 outside of bucket range, discarded.\n",
      "Node 188 outside of bucket range, discarded.\n",
      "Node 189 outside of bucket range, discarded.\n",
      "Node 190 outside of bucket range, discarded.\n",
      "Node 191 outside of bucket range, discarded.\n",
      "Node 192 outside of bucket range, discarded.\n",
      "Node 193 outside of bucket range, discarded.\n",
      "Node 194 outside of bucket range, discarded.\n",
      "Node 195 outside of bucket range, discarded.\n",
      "Node 196 outside of bucket range, discarded.\n",
      "Node 197 outside of bucket range, discarded.\n",
      "Node 198 outside of bucket range, discarded.\n",
      "Node 199 outside of bucket range, discarded.\n",
      "Node 200 outside of bucket range, discarded.\n",
      "Node 201 outside of bucket range, discarded.\n",
      "Node 202 outside of bucket range, discarded.\n",
      "Node 203 outside of bucket range, discarded.\n",
      "Node 204 outside of bucket range, discarded.\n",
      "Node 205 outside of bucket range, discarded.\n",
      "Peer 001 bucket contents:\n",
      "025\n",
      "031\n",
      "033\n",
      "Peer 002 bucket contents:\n",
      "022\n",
      "026\n",
      "030\n",
      "Peer 003 bucket contents:\n",
      "037\n",
      "041\n",
      "042\n",
      "Peer 004 bucket contents:\n",
      "018\n",
      "020\n",
      "021\n",
      "Peer 005 bucket contents:\n",
      "028\n",
      "029\n",
      "032\n"
     ]
    }
   ],
   "source": [
    "# 模拟多节点\n",
    "import hashlib\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node_id):\n",
    "        self.id = node_id\n",
    "\n",
    "class KBucket:\n",
    "    def __init__(self, depth, capacity=3, range_start=0, range_end=(1 << 160) - 1):\n",
    "        self.nodes = []\n",
    "        self.capacity = capacity\n",
    "        self.depth = depth\n",
    "        self.range_start = range_start\n",
    "        self.range_end = range_end\n",
    "\n",
    "    def insert_node(self, node_id):\n",
    "        if len(self.nodes) < self.capacity:\n",
    "            self.nodes.append(Node(node_id))\n",
    "        else:\n",
    "            if self.node_in_bucket_range(node_id):\n",
    "                self.split_bucket()\n",
    "                self.insert_node(node_id)\n",
    "            else:\n",
    "                print(f\"Node {node_id} outside of bucket range, discarded.\")\n",
    "\n",
    "    def node_in_bucket_range(self, node_id):\n",
    "        node_id_num = int(node_id, 16)\n",
    "        return self.range_start <= node_id_num <= self.range_end\n",
    "\n",
    "    def split_bucket(self):\n",
    "        mid_point = (self.range_start + self.range_end) // 2\n",
    "        left_bucket = KBucket(self.depth + 1, self.capacity, self.range_start, mid_point)\n",
    "        right_bucket = KBucket(self.depth + 1, self.capacity, mid_point + 1, self.range_end)\n",
    "        for node in self.nodes:\n",
    "            if self.range_start <= int(node.id, 16) <= mid_point:\n",
    "                left_bucket.nodes.append(node)\n",
    "            else:\n",
    "                right_bucket.nodes.append(node)\n",
    "        self.nodes = []\n",
    "        self.nodes.extend(left_bucket.nodes if len(left_bucket.nodes) <= len(right_bucket.nodes) else right_bucket.nodes)\n",
    "        self.range_start = left_bucket.range_start if len(left_bucket.nodes) <= len(right_bucket.nodes) else right_bucket.range_start\n",
    "        self.range_end = left_bucket.range_end if len(left_bucket.nodes) <= len(right_bucket.nodes) else right_bucket.range_end\n",
    "        print(\"Bucket split into two new buckets\")\n",
    "\n",
    "    def find_node(self, node_id):\n",
    "        for node in self.nodes:\n",
    "            if node.id == node_id:\n",
    "                return [node.id]\n",
    "        # Node not found, return 2 random nodes if possible\n",
    "        return [node.id for node in random.sample(self.nodes, min(2, len(self.nodes)))]\n",
    "\n",
    "    def print_contents(self):\n",
    "        for node in self.nodes:\n",
    "            print(node.id)\n",
    "\n",
    "class Peer:\n",
    "    def __init__(self, node_id):\n",
    "        self.id = node_id\n",
    "        self.bucket = KBucket(depth=0)\n",
    "\n",
    "    def broadcast_new_node(self, new_node_id):\n",
    "        self.bucket.insert_node(new_node_id)\n",
    "\n",
    "def initialize_network():\n",
    "    initial_peers = [Peer(f'{i:03}') for i in range(1, 6)]\n",
    "    new_peers = [f'{i:03}' for i in range(6, 206)]\n",
    "    for new_peer_id in new_peers:\n",
    "        random.choice(initial_peers).broadcast_new_node(new_peer_id)\n",
    "\n",
    "    for peer in initial_peers:\n",
    "        print(f\"Peer {peer.id} bucket contents:\")\n",
    "        peer.bucket.print_contents()\n",
    "\n",
    "initialize_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验二\n",
    "\n",
    "class KBucket:\n",
    "    def __init__(self, depth, capacity=160, range_start=0, range_end=(1 << 160) - 1):\n",
    "        self.peers = []\n",
    "        self.capacity = capacity\n",
    "        self.depth = depth\n",
    "        self.range_start = range_start\n",
    "        self.range_end = range_end\n",
    "\n",
    "    def insert_peer(self, peer):\n",
    "        if len(self.peers) < self.capacity:\n",
    "            self.peers.append(peer)\n",
    "        else:\n",
    "            if self.peer_in_bucket_range(peer.id):\n",
    "                self.split_bucket()\n",
    "                self.insert_peer(peer)\n",
    "            else:\n",
    "                print(f\"Peer {peer.id} outside of bucket range, discarded.\")\n",
    "\n",
    "    def peer_in_bucket_range(self, peer_id):\n",
    "        peer_id_num = int(peer_id, 16)\n",
    "        return self.range_start <= peer_id_num <= self.range_end\n",
    "\n",
    "    def split_bucket(self):\n",
    "        mid_point = (self.range_start + self.range_end) // 2\n",
    "        left_bucket = KBucket(self.depth + 1, self.capacity, self.range_start, mid_point)\n",
    "        right_bucket = KBucket(self.depth + 1, self.capacity, mid_point + 1, self.range_end)\n",
    "        for peer in self.peers:\n",
    "            if self.range_start <= int(peer.id, 16) <= mid_point:\n",
    "                left_bucket.peers.append(peer)\n",
    "            else:\n",
    "                right_bucket.peers.append(peer)\n",
    "        self.peers = []\n",
    "        self.peers.extend(left_bucket.peers if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.peers)\n",
    "        self.range_start = left_bucket.range_start if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.range_start\n",
    "        self.range_end = left_bucket.range_end if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.range_end\n",
    "\n",
    "    def find_closest_peers(self, key, count=2):\n",
    "        # Simple placeholder to return closest peers; actual implementation would use a more sophisticated metric\n",
    "        return sorted(self.peers, key=lambda peer: abs(int(peer.id, 16) - int(key, 16)))[:count]\n",
    "\n",
    "    def printBucketContents(self):\n",
    "        for peer in self.peers:\n",
    "            print(peer.id)\n",
    "\n",
    "\n",
    "import hashlib\n",
    "\n",
    "class Peer:\n",
    "    def __init__(self, node_id):\n",
    "        self.id = node_id\n",
    "        self.bucket = KBucket(depth=0)\n",
    "        self.storage = {}\n",
    "\n",
    "    def set_value(self, key, value):\n",
    "        key_hash = hashlib.sha1(key).hexdigest()\n",
    "        if key_hash != value.hex():\n",
    "            return False\n",
    "        if key in self.storage:\n",
    "            return True\n",
    "        self.storage[key] = value\n",
    "        closest_peers = self.bucket.find_closest_peers(key_hash)\n",
    "        for peer in closest_peers:\n",
    "            peer.set_value(key, value)\n",
    "        return True\n",
    "\n",
    "    def get_value(self, key):\n",
    "        if key in self.storage:\n",
    "            return self.storage[key]\n",
    "        closest_peers = self.bucket.find_closest_peers(key)\n",
    "        for peer in closest_peers:\n",
    "            value = peer.get_value(key)\n",
    "            if value:\n",
    "                return value\n",
    "        return None\n",
    "\n",
    "    def broadcast_new_peer(self, new_peer):\n",
    "        self.bucket.insert_peer(new_peer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# 有问题的实现\n",
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "\n",
    "class KBucket:\n",
    "    def __init__(self, depth, capacity=160, range_start=0, range_end=(1 << 160) - 1):\n",
    "        self.peers = []\n",
    "        self.capacity = capacity\n",
    "        self.depth = depth\n",
    "        self.range_start = range_start\n",
    "        self.range_end = range_end\n",
    "\n",
    "    def insert_peer(self, peer):\n",
    "        if len(self.peers) < self.capacity:\n",
    "            self.peers.append(peer)\n",
    "        else:\n",
    "            if self.peer_in_bucket_range(peer.id):\n",
    "                self.split_bucket()\n",
    "                self.insert_peer(peer)\n",
    "            else:\n",
    "                print(f\"Peer {peer.id} outside of bucket range, discarded.\")\n",
    "\n",
    "    def peer_in_bucket_range(self, peer_id):\n",
    "        peer_id_num = int(peer_id, 16)\n",
    "        return self.range_start <= peer_id_num <= self.range_end\n",
    "\n",
    "    def split_bucket(self):\n",
    "        mid_point = (self.range_start + self.range_end) // 2\n",
    "        left_bucket = KBucket(self.depth + 1, self.capacity, self.range_start, mid_point)\n",
    "        right_bucket = KBucket(self.depth + 1, self.capacity, mid_point + 1, self.range_end)\n",
    "        for peer in self.peers:\n",
    "            if self.range_start <= int(peer.id, 16) <= mid_point:\n",
    "                left_bucket.peers.append(peer)\n",
    "            else:\n",
    "                right_bucket.peers.append(peer)\n",
    "        self.peers = []\n",
    "        self.peers.extend(left_bucket.peers if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.peers)\n",
    "        self.range_start = left_bucket.range_start if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.range_start\n",
    "        self.range_end = left_bucket.range_end if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.range_end\n",
    "\n",
    "    def find_closest_peers(self, key, count=2):\n",
    "        return sorted(self.peers, key=lambda peer: abs(int(peer.id, 16) - int(key, 16)))[:count]\n",
    "\n",
    "class Peer:\n",
    "    def __init__(self, node_id):\n",
    "        self.id = node_id\n",
    "        self.bucket = KBucket(depth=0)\n",
    "        self.storage = {}\n",
    "\n",
    "    def set_value(self, key, value, depth=0):\n",
    "        if depth > 3:  # 限制递归深度为3\n",
    "            return False\n",
    "        key_hash = hashlib.sha1(key.encode()).hexdigest()\n",
    "        if key_hash != hashlib.sha1(value.encode()).hexdigest():\n",
    "            return False\n",
    "        if key in self.storage:\n",
    "            return True\n",
    "        self.storage[key] = value\n",
    "        closest_peers = self.bucket.find_closest_peers(key_hash)\n",
    "        for peer in closest_peers:\n",
    "            peer.set_value(key, value, depth + 1)  # 递增递归深度\n",
    "        return True\n",
    "\n",
    "    def get_value(self, key):\n",
    "        if key in self.storage:\n",
    "            return self.storage[key]\n",
    "        closest_peers = self.bucket.find_closest_peers(key)\n",
    "        for peer in closest_peers:\n",
    "            value = peer.get_value(key)\n",
    "            if value:\n",
    "                return value\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Initialize 100 peers\n",
    "    peers = [Peer(f'{i:03}') for i in range(100)]\n",
    "\n",
    "    # Generate 200 random strings and their hashes\n",
    "    keys = []\n",
    "    for _ in range(200):\n",
    "        random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=random.randint(5, 20)))\n",
    "        key = hashlib.sha1(random_string.encode()).hexdigest()\n",
    "        keys.append(key)\n",
    "        chosen_peer = random.choice(peers)\n",
    "        chosen_peer.set_value(key, random_string)\n",
    "\n",
    "    # Retrieve 100 random keys\n",
    "    retrieved_values = []\n",
    "    for key in random.sample(keys, 100):\n",
    "        chosen_peer = random.choice(peers)\n",
    "        value = chosen_peer.get_value(key)\n",
    "        retrieved_values.append(value)\n",
    "\n",
    "    # Print retrieved values\n",
    "    print(retrieved_values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value retrieved: b'Z`\\\\\\xf2\\xd5}2w\\xab\\xe4\\x93|\\xb2\\x8a\\xd0,\\xa5\\x89\\xf91'\n",
      "Value retrieved: b'\\xd2<\\xf7\\x9b\\xd3\\xad\\x03p\\xd9\\xae4\\xe4\\xed\\xb4;\\xd5S+1\\xbf'\n",
      "No values stored for peer 015\n",
      "Value retrieved: b'\\xab\\xed0\\x17\\xb8\\xae\\xe7\\x01\\xaa\\x01Q\\x1ec\\xaa\\xbb\\x92a\\xfb\\x99G'\n",
      "Value retrieved: b'\\xb0`\\x9b$;:\\x9dWQ\\x98\\x8b\\x96\\x92\\xec\\xf7\\xb2B\\xa1s\\xa5'\n",
      "No values stored for peer 091\n",
      "Value retrieved: b'Bk\\x04\\xd8\\x08WB\\xa4H\\xe6\\xc8`\\x96\\xe1\\x88\\xc2(y\\xe4\\xdc'\n",
      "Value retrieved: b'\\xb0`\\x9b$;:\\x9dWQ\\x98\\x8b\\x96\\x92\\xec\\xf7\\xb2B\\xa1s\\xa5'\n",
      "Value retrieved: b'\\xb0`\\x9b$;:\\x9dWQ\\x98\\x8b\\x96\\x92\\xec\\xf7\\xb2B\\xa1s\\xa5'\n",
      "No values stored for peer 004\n"
     ]
    }
   ],
   "source": [
    "# 简化了KBucket\n",
    "\n",
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "\n",
    "def calculate_distance(id1, id2):\n",
    "    return int(id1, 16) ^ int(id2, 16)\n",
    "\n",
    "class KBucket: # 用实验一的实现有点复杂没能跑通\n",
    "    def __init__(self, capacity=160):\n",
    "        self.peers = []\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def insert_peer(self, peer):\n",
    "        if len(self.peers) < self.capacity:\n",
    "            self.peers.append(peer)\n",
    "\n",
    "    def find_closest_peers(self, key, count=5):\n",
    "        return sorted(self.peers, key=lambda peer: calculate_distance(peer.id, key))[:count]\n",
    "\n",
    "class DHT:\n",
    "    def __init__(self):\n",
    "        self.buckets = [KBucket() for _ in range(160)]\n",
    "\n",
    "class Peer:\n",
    "    def __init__(self, node_id, dht):\n",
    "        self.id = node_id\n",
    "        self.dht = dht\n",
    "        self.storage = {}\n",
    "\n",
    "    def set_value(self, key, value, depth=0, tried_peers=None):\n",
    "        if depth > 10 or tried_peers and self.id in tried_peers:\n",
    "            return False\n",
    "        tried_peers = tried_peers or set()\n",
    "        tried_peers.add(self.id)\n",
    "\n",
    "        key_hash = hashlib.sha1(key).hexdigest()\n",
    "        self.storage[key] = value\n",
    "        bucket_index = self.calculate_bucket_index(key_hash)\n",
    "        closest_peers = self.dht.buckets[bucket_index].find_closest_peers(key_hash)\n",
    "        for peer in closest_peers:\n",
    "            if peer.id not in tried_peers:\n",
    "                peer.set_value(key, value, depth + 1, tried_peers)\n",
    "        return True\n",
    "\n",
    "    def get_value(self, key):\n",
    "        if key in self.storage:\n",
    "            return self.storage[key]\n",
    "        key_hash = hashlib.sha1(key).hexdigest()\n",
    "        bucket_index = self.calculate_bucket_index(key_hash)\n",
    "        closest_peers = self.dht.buckets[bucket_index].find_closest_peers(key_hash)\n",
    "        for peer in closest_peers:\n",
    "            value = peer.get_value(key)\n",
    "            if value:\n",
    "                return value\n",
    "        return None\n",
    "\n",
    "    def calculate_bucket_index(self, key_hash):\n",
    "        combined_hash = hashlib.sha1((self.id + key_hash).encode()).hexdigest()\n",
    "        return int(combined_hash, 16) % 160\n",
    "\n",
    "def main():\n",
    "    dht = DHT()\n",
    "    peers = [Peer(f'{i:03}', dht) for i in range(100)]\n",
    "    for peer in peers:\n",
    "        initial_bucket_index = int(hashlib.sha1(peer.id.encode()).hexdigest(), 16) % 160\n",
    "        dht.buckets[initial_bucket_index].insert_peer(peer)\n",
    "\n",
    "    for _ in range(20): # 200太大了好像会崩溃\n",
    "        random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "        key = random_string.encode()\n",
    "        value = hashlib.sha1(key).digest()\n",
    "        chosen_peer = random.choice(peers)\n",
    "        chosen_peer.set_value(key, value)\n",
    "\n",
    "    for _ in range(10): # 对应的取到了10个\n",
    "        chosen_peer = random.choice(peers)\n",
    "        if chosen_peer.storage:\n",
    "            key = random.choice(list(chosen_peer.storage.keys()))\n",
    "            value = chosen_peer.get_value(key)\n",
    "            if value:\n",
    "                print(f\"Value retrieved: {value}\")\n",
    "            else:\n",
    "                print(\"Value retrieval failed.\")\n",
    "        else:\n",
    "            print(f\"No values stored for peer {chosen_peer.id}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No values stored for peer 026\n",
      "No values stored for peer 036\n",
      "No values stored for peer 021\n",
      "No values stored for peer 086\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 144\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo values stored for peer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchosen_peer\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[4], line 135\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chosen_peer\u001b[38;5;241m.\u001b[39mstorage:\n\u001b[0;32m    134\u001b[0m     key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlist\u001b[39m(chosen_peer\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m--> 135\u001b[0m     value \u001b[38;5;241m=\u001b[39m chosen_peer\u001b[38;5;241m.\u001b[39mget_value(key)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue retrieved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 97\u001b[0m, in \u001b[0;36mPeer.get_value\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     95\u001b[0m closest_peers \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mfind_closest_peers(key_hash)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m peer \u001b[38;5;129;01min\u001b[39;00m closest_peers:\n\u001b[1;32m---> 97\u001b[0m     value \u001b[38;5;241m=\u001b[39m peer\u001b[38;5;241m.\u001b[39mget_value(key)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "Cell \u001b[1;32mIn[4], line 97\u001b[0m, in \u001b[0;36mPeer.get_value\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     95\u001b[0m closest_peers \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mfind_closest_peers(key_hash)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m peer \u001b[38;5;129;01min\u001b[39;00m closest_peers:\n\u001b[1;32m---> 97\u001b[0m     value \u001b[38;5;241m=\u001b[39m peer\u001b[38;5;241m.\u001b[39mget_value(key)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "    \u001b[1;31m[... skipping similar frames: Peer.get_value at line 97 (2966 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[4], line 97\u001b[0m, in \u001b[0;36mPeer.get_value\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     95\u001b[0m closest_peers \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mfind_closest_peers(key_hash)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m peer \u001b[38;5;129;01min\u001b[39;00m closest_peers:\n\u001b[1;32m---> 97\u001b[0m     value \u001b[38;5;241m=\u001b[39m peer\u001b[38;5;241m.\u001b[39mget_value(key)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "Cell \u001b[1;32mIn[4], line 95\u001b[0m, in \u001b[0;36mPeer.get_value\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     93\u001b[0m bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdht\u001b[38;5;241m.\u001b[39mfind_bucket_for_key(key_hash)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bucket:\n\u001b[1;32m---> 95\u001b[0m     closest_peers \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mfind_closest_peers(key_hash)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m peer \u001b[38;5;129;01min\u001b[39;00m closest_peers:\n\u001b[0;32m     97\u001b[0m         value \u001b[38;5;241m=\u001b[39m peer\u001b[38;5;241m.\u001b[39mget_value(key)\n",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m, in \u001b[0;36mKBucket.find_closest_peers\u001b[1;34m(self, key, count)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_closest_peers\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeers, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m peer: \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mint\u001b[39m(peer\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;241m16\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(key, \u001b[38;5;241m16\u001b[39m)))[:count]\n",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m, in \u001b[0;36mKBucket.find_closest_peers.<locals>.<lambda>\u001b[1;34m(peer)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_closest_peers\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeers, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m peer: \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mint\u001b[39m(peer\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;241m16\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(key, \u001b[38;5;241m16\u001b[39m)))[:count]\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "# Dev版本,尚未完全实现\n",
    "\n",
    "import hashlib\n",
    "import random\n",
    "import string\n",
    "\n",
    "def calculate_distance(id1, id2):\n",
    "    return int(id1, 16) ^ int(id2, 16)\n",
    "\n",
    "class KBucket:\n",
    "    def __init__(self, depth, capacity=160, range_start=0, range_end=(1 << 160) - 1):\n",
    "        self.peers = []\n",
    "        self.capacity = capacity\n",
    "        self.depth = depth\n",
    "        self.range_start = range_start\n",
    "        self.range_end = range_end\n",
    "\n",
    "    def insert_peer(self, peer):\n",
    "        if len(self.peers) < self.capacity:\n",
    "            self.peers.append(peer)\n",
    "        else:\n",
    "            if self.peer_in_bucket_range(peer.id):\n",
    "                self.split_bucket()\n",
    "                self.insert_peer(peer)\n",
    "            else:\n",
    "                print(f\"Peer {peer.id} outside of bucket range, discarded.\")\n",
    "\n",
    "    def peer_in_bucket_range(self, peer_id):\n",
    "        peer_id_num = int(peer_id, 16)\n",
    "        return self.range_start <= peer_id_num <= self.range_end\n",
    "\n",
    "    def split_bucket(self):\n",
    "        mid_point = (self.range_start + self.range_end) // 2\n",
    "        left_bucket = KBucket(self.depth + 1, self.capacity, self.range_start, mid_point)\n",
    "        right_bucket = KBucket(self.depth + 1, self.capacity, mid_point + 1, self.range_end)\n",
    "        for peer in self.peers:\n",
    "            if self.range_start <= int(peer.id, 16) <= mid_point:\n",
    "                left_bucket.peers.append(peer)\n",
    "            else:\n",
    "                right_bucket.peers.append(peer)\n",
    "        self.peers = []\n",
    "        self.peers.extend(left_bucket.peers if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.peers)\n",
    "        self.range_start = left_bucket.range_start if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.range_start\n",
    "        self.range_end = left_bucket.range_end if len(left_bucket.peers) <= len(right_bucket.peers) else right_bucket.range_end\n",
    "\n",
    "    def find_closest_peers(self, key, count=2):\n",
    "        return sorted(self.peers, key=lambda peer: abs(int(peer.id, 16) - int(key, 16)))[:count]\n",
    "\n",
    "class DHT:\n",
    "    def __init__(self):\n",
    "        self.buckets = [KBucket(depth=0, capacity=160, range_start=0, range_end=(1 << 160) - 1)]\n",
    "\n",
    "    def find_bucket_for_key(self, key_hash):\n",
    "        for bucket in self.buckets:\n",
    "            if bucket.peer_in_bucket_range(key_hash):\n",
    "                return bucket\n",
    "        return None\n",
    "\n",
    "    def insert_peer(self, peer):\n",
    "        peer_id_num = int(peer.id, 16)\n",
    "        bucket = self.find_bucket_for_key(peer.id)\n",
    "        if bucket:\n",
    "            bucket.insert_peer(peer)\n",
    "        else:\n",
    "            print(f\"Peer {peer.id} could not be placed in any bucket.\")\n",
    "\n",
    "class Peer:\n",
    "    def __init__(self, node_id, dht):\n",
    "        self.id = node_id\n",
    "        self.dht = dht\n",
    "        self.storage = {}\n",
    "\n",
    "    def set_value(self, key, value, depth=0, tried_peers=None):\n",
    "        if depth > 10 or (tried_peers and self.id in tried_peers):\n",
    "            return False\n",
    "        tried_peers = tried_peers or set()\n",
    "        tried_peers.add(self.id)\n",
    "\n",
    "        key_hash = hashlib.sha1(key).hexdigest()\n",
    "        self.storage[key] = value\n",
    "        bucket = self.dht.find_bucket_for_key(key_hash)\n",
    "        if bucket:\n",
    "            closest_peers = bucket.find_closest_peers(key_hash)\n",
    "            for peer in closest_peers:\n",
    "                if peer.id not in tried_peers:\n",
    "                    peer.set_value(key, value, depth + 1, tried_peers)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_value(self, key):\n",
    "        key_hash = hashlib.sha1(key).hexdigest()\n",
    "        bucket = self.dht.find_bucket_for_key(key_hash)\n",
    "        if bucket:\n",
    "            closest_peers = bucket.find_closest_peers(key_hash)\n",
    "            for peer in closest_peers:\n",
    "                value = peer.get_value(key)\n",
    "                if value:\n",
    "                    return value\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    dht = DHT()\n",
    "    # Initialize buckets\n",
    "    initial_range = (1 << 160) - 1\n",
    "    initial_buckets = [KBucket(depth=0, capacity=160, range_start=0, range_end=initial_range)]\n",
    "    dht.buckets = initial_buckets\n",
    "    \n",
    "    # Initialize peers\n",
    "    peers = [Peer(f'{i:03}', dht) for i in range(100)]\n",
    "    for peer in peers:\n",
    "\n",
    "        placed = False\n",
    "        for bucket in dht.buckets:\n",
    "            if bucket.peer_in_bucket_range(peer.id):\n",
    "                bucket.insert_peer(peer)\n",
    "                placed = True\n",
    "                break\n",
    "        if not placed:\n",
    "            print(f\"Peer {peer.id} could not be placed in any bucket.\")\n",
    "\n",
    "    # Set and retrieve values\n",
    "    for _ in range(20):\n",
    "        random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "        key = random_string.encode()\n",
    "        value = hashlib.sha1(key).digest()\n",
    "        chosen_peer = random.choice(peers)\n",
    "        chosen_peer.set_value(key, value)\n",
    "\n",
    "    for _ in range(10):\n",
    "        chosen_peer = random.choice(peers)\n",
    "        if chosen_peer.storage:\n",
    "            key = random.choice(list(chosen_peer.storage.keys()))\n",
    "            value = chosen_peer.get_value(key)\n",
    "            if value:\n",
    "                print(f\"Value retrieved: {value}\")\n",
    "            else:\n",
    "                print(\"Value retrieval failed.\")\n",
    "        else:\n",
    "            print(f\"No values stored for peer {chosen_peer.id}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
